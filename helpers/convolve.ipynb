{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56652ba",
   "metadata": {},
   "source": [
    "# Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c958da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x111782f90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "th.backends.quantized.engine = \"qnnpack\"  # for ARM CPU\n",
    "th.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a239e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(th.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=1,\n",
    "        padding=1,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.quant = th.ao.quantization.QuantStub()\n",
    "        self.conv = th.nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding,\n",
    "            dilation,\n",
    "            groups,\n",
    "            bias,\n",
    "        )\n",
    "        self.dequant = th.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af16c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 2\n",
    "output_channels = 2\n",
    "input_width = 3\n",
    "input_height = 3\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 1\n",
    "dilation = 1\n",
    "groups = 1\n",
    "bias = False\n",
    "m = Model(\n",
    "    input_channels,\n",
    "    output_channels,\n",
    "    kernel_size,\n",
    "    stride,\n",
    "    padding,\n",
    "    dilation,\n",
    "    groups,\n",
    "    bias=bias,\n",
    ")\n",
    "\n",
    "m.qconfig = th.ao.quantization.QConfig(\n",
    "    activation=th.ao.quantization.MovingAverageMinMaxObserver.with_args(\n",
    "        quant_min=-128,\n",
    "        quant_max=127,\n",
    "        dtype=th.qint8,\n",
    "        qscheme=th.per_tensor_symmetric,\n",
    "        reduce_range=False,\n",
    "    ),\n",
    "    weight=th.ao.quantization.MovingAverageMinMaxObserver.with_args(\n",
    "        quant_min=-128,\n",
    "        quant_max=127,\n",
    "        dtype=th.qint8,\n",
    "        qscheme=th.per_tensor_symmetric,\n",
    "        reduce_range=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Prepare\n",
    "pm = th.ao.quantization.prepare_qat(m)\n",
    "\n",
    "# Train\n",
    "pm(th.rand(32, input_channels, input_width, input_height))\n",
    "\n",
    "# Convert\n",
    "qm = th.ao.quantization.convert(pm.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25095119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float input: tensor([0.1022, 0.3797, 0.7720, 0.2957, 0.9200, 0.1559, 0.0801, 0.2745, 0.5808,\n",
      "        0.9604, 0.2613, 0.6788, 0.3746, 0.3916, 0.8677, 0.1125, 0.5531, 0.9702])\n",
      "\n",
      "Quantized input: tensor([[[[ 13,  48,  98],\n",
      "          [ 38, 117,  20],\n",
      "          [ 10,  35,  74]],\n",
      "\n",
      "         [[122,  33,  87],\n",
      "          [ 48,  50, 111],\n",
      "          [ 14,  71, 124]]]], dtype=torch.int8)\n",
      "\n",
      "Permuted Quantized input: tensor([ 13, 122,  48,  33,  98,  87,  38,  48, 117,  50,  20, 111,  10,  14,\n",
      "         35,  71,  74, 124], dtype=torch.int8)\n",
      "\n",
      "Float output: tensor([[[[-0.0336,  0.0056, -0.1902],\n",
      "          [-0.1063, -0.2182, -0.1287],\n",
      "          [-0.2462, -0.1678, -0.3972]],\n",
      "\n",
      "         [[ 0.2686, -0.2574, -0.0671],\n",
      "          [-0.0504, -0.5147, -0.2014],\n",
      "          [-0.0504, -0.2630, -0.2070]]]])\n",
      "\n",
      "Quantized output: tensor([[[[ -6.,   1., -34.],\n",
      "          [-19., -39., -23.],\n",
      "          [-44., -30., -71.]],\n",
      "\n",
      "         [[ 48., -46., -12.],\n",
      "          [ -9., -92., -36.],\n",
      "          [ -9., -47., -37.]]]])\n",
      "\n",
      "Permuted Quantized output: tensor([ -6.,  48.,   1., -46., -34., -12., -19.,  -9., -39., -92., -23., -36.,\n",
      "        -44.,  -9., -30., -47., -71., -37.])\n",
      "\n",
      "Multiplier: tensor([5315931.])\n",
      "\n",
      "Quantized weights: tensor([[[[  -1,   72, -110],\n",
      "          [ -98,  -51,   36],\n",
      "          [  -3,  106,  -12]],\n",
      "\n",
      "         [[  35,  -40,  -26],\n",
      "          [-128,  -88,  -55],\n",
      "          [   5,   53,   80]]],\n",
      "\n",
      "\n",
      "        [[[ -90,  -58,   48],\n",
      "          [ 111,  -27,  100],\n",
      "          [ -22,   14,  121]],\n",
      "\n",
      "         [[-124,  -84,  -34],\n",
      "          [ -52,  115,  -87],\n",
      "          [ -61,  -93, -125]]]], dtype=torch.int32)\n",
      "\n",
      "Permuted Quantized weights: tensor([  -1,   35,   72,  -40, -110,  -26,  -98, -128,  -51,  -88,   36,  -55,\n",
      "          -3,    5,  106,   53,  -12,   80,  -90, -124,  -58,  -84,   48,  -34,\n",
      "         111,  -52,  -27,  115,  100,  -87,  -22,  -61,   14,  -93,  121, -125],\n",
      "       dtype=torch.int32)\n",
      "\n",
      "Quantized bias: tensor([0, 0], dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "x = th.rand(1, input_channels, input_width, input_height)\n",
    "xq = qm.quant(x)\n",
    "y = qm(x)\n",
    "yq = th.round(y / qm.conv.scale)\n",
    "pdims = (0, 2, 3, 1)  # permutation dimensions\n",
    "\n",
    "print(f\"Float input: {x.flatten()}\\n\")\n",
    "print(f\"Quantized input: {xq.int_repr()}\\n\")\n",
    "print(f\"Permuted Quantized input: {xq.int_repr().permute(pdims).flatten()}\\n\")\n",
    "print(f\"Float output: {y}\\n\")\n",
    "print(f\"Quantized output: {yq}\\n\")\n",
    "print(f\"Permuted Quantized output: {yq.permute(pdims).flatten()}\\n\")\n",
    "print(\n",
    "    f\"Multiplier: {th.round((qm.quant.scale * qm.conv.weight().q_scale() / qm.conv.scale) * (2**31))}\\n\"\n",
    ")\n",
    "print(f\"Quantized weights: {qm.conv.weight().int_repr().int()}\\n\")\n",
    "print(\n",
    "    f\"Permuted Quantized weights: {qm.conv.weight().int_repr().permute(pdims).flatten().int()}\\n\"\n",
    "    # f\"Permuted Quantized weights: {qm.conv.weight().int_repr().flatten()}\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"Quantized bias: {th.round(qm.conv.bias() / (qm.quant.scale * qm.conv.weight().q_scale())).int()}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93775824",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_two = qm.conv.weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25bbfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  -1,   72, -110,  -98,  -51,   36,   -3,  106,  -12,   35,  -40,  -26,\n",
       "        -128,  -88,  -55,    5,   53,   80,  -90,  -58,   48,  111,  -27,  100,\n",
       "         -22,   14,  121, -124,  -84,  -34,  -52,  115,  -87,  -61,  -93, -125],\n",
       "       dtype=torch.int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_two.int_repr().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138177a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'two_one' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m one_two.int_repr(), \u001b[43mtwo_one\u001b[49m.int_repr(), one_two.shape, two_one.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'two_one' is not defined"
     ]
    }
   ],
   "source": [
    "one_two.int_repr(), two_one.int_repr(), one_two.shape, two_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (0, 2, 3, 1)\n",
    "print(one_two.int_repr().permute(dims).flatten())\n",
    "print(two_one.int_repr().permute(dims).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_one = qm.conv.weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_one.permute(2, 3, 0, 1).flatten().int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ce220",
   "metadata": {},
   "outputs": [],
   "source": [
    "xq.int_repr().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm.conv.weight().int_repr().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99faf22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
