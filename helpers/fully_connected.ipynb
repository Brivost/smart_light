{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56652ba",
   "metadata": {},
   "source": [
    "# Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c958da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11929ef90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "th.backends.quantized.engine = \"qnnpack\"  # for ARM CPU\n",
    "th.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a239e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(th.nn.Module):\n",
    "    def __init__(self, input_dims, output_dims, bias=False):\n",
    "        super().__init__()\n",
    "        self.quant = th.ao.quantization.QuantStub()\n",
    "        self.fc = th.nn.Linear(input_dims, output_dims, bias=bias)\n",
    "        self.dequant = th.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af16c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = 10\n",
    "output_dims = 15\n",
    "m = Model(input_dims, output_dims, bias=True)\n",
    "\n",
    "m.qconfig = th.ao.quantization.QConfig(\n",
    "    activation=th.ao.quantization.MovingAverageMinMaxObserver.with_args(\n",
    "        quant_min=-128,\n",
    "        quant_max=127,\n",
    "        dtype=th.qint8,\n",
    "        qscheme=th.per_tensor_symmetric,\n",
    "        reduce_range=False,\n",
    "    ),\n",
    "    weight=th.ao.quantization.MovingAverageMinMaxObserver.with_args(\n",
    "        quant_min=-128,\n",
    "        quant_max=127,\n",
    "        dtype=th.qint8,\n",
    "        qscheme=th.per_tensor_symmetric,\n",
    "        reduce_range=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Prepare\n",
    "pm = th.ao.quantization.prepare_qat(m)\n",
    "\n",
    "# Train\n",
    "pm(th.rand(32, input_dims))\n",
    "\n",
    "# Convert\n",
    "qm = th.ao.quantization.convert(pm.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25095119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float input: tensor([[0.7720, 0.2957, 0.9200, 0.1559, 0.0801, 0.2745, 0.5808, 0.9604, 0.2613,\n",
      "         0.6788]])\n",
      "\n",
      "Quantized input: tensor([[ 98,  38, 117,  20,  10,  35,  74, 122,  33,  87]], dtype=torch.int8)\n",
      "\n",
      "Float output: tensor([[-0.2249, -0.5709, -0.1384,  0.1470,  0.3287, -0.3373,  0.5276, -0.5709,\n",
      "         -0.3114,  0.1211, -0.2768, -0.2595, -0.7784, -0.3546,  0.3633]])\n",
      "\n",
      "Quantized output: tensor([[-26., -66., -16.,  17.,  38., -39.,  61., -66., -36.,  14., -32., -30.,\n",
      "         -90., -41.,  42.]])\n",
      "\n",
      "Multiplier: tensor([4817036.])\n",
      "\n",
      "Quantized weights: tensor([  -1,   69, -105,  -94,  -49,   34,   -3,  101,  -11,   34,  -39,  -25,\n",
      "        -122,  -85,  -53,    5,   51,   77,  -87,  -56,   46,  106,  -26,   96,\n",
      "         -21,   14,  116, -119,  -80,  -32,  -50,  110,  -83,  -59,  -89, -120,\n",
      "         -75,  110,   57,   62,    7,  -66,   22, -119,  -92,  -66,   81,   75,\n",
      "         -57,   -5,   82,  127,   51,   17,   86,  -75,   24,  -99,  -89,  -66,\n",
      "          58,   51,  -76,   39,   70,  -16,    5,   30,   79,  123,  -98,  -47,\n",
      "          50,  106,  111,  113,   25, -111,   12,  -80, -119,  114,   97, -128,\n",
      "          24,  -22,  -21,  -59,   49,  -76,   47,   65,   91,   48, -127,  -83,\n",
      "          64,   27, -100,  -74,  120,   86,  -56,  -32, -122,   -2,  -96,  -99,\n",
      "          -7,   19,  -52,   76,  -78,  116,   88, -108,  -32,    6,   19,   30,\n",
      "          50,    8,  -62,   60, -123,  -76,  -32,  -62,  -45, -105,  -27,   27,\n",
      "         -83,   -7,   91,  -13,    4,  -11,   26,   81,  121,   81,  121,   -9,\n",
      "        -115,  -61,   87,   -1,  -64,  -98], dtype=torch.int8)\n",
      "\n",
      "Quantized bias: tensor([-15254, -13757,  -3306,   8939,   8812, -15719,  10167, -12754,  -3446,\n",
      "         -6609,  -3139,  -3200, -14626, -14073,  -2550], dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "x = th.rand(1, input_dims)\n",
    "xq = qm.quant(x)\n",
    "y = qm(x)\n",
    "yq = th.round(y / qm.fc.scale)\n",
    "\n",
    "print(f\"Float input: {x}\\n\")\n",
    "print(f\"Quantized input: {xq.int_repr()}\\n\")\n",
    "print(f\"Float output: {y}\\n\")\n",
    "print(f\"Quantized output: {yq}\\n\")\n",
    "print(\n",
    "    f\"Multiplier: {th.round((qm.quant.scale * qm.fc.weight().q_scale() / qm.fc.scale) * (2**31))}\\n\"\n",
    ")\n",
    "print(f\"Quantized weights: {qm.fc.weight().int_repr().flatten()}\\n\")\n",
    "print(\n",
    "    f\"Quantized bias: {th.round(qm.fc.bias() / (qm.quant.scale * qm.fc.weight().q_scale())).int()}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01118ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
