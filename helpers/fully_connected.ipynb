{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56652ba",
   "metadata": {},
   "source": [
    "# Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c958da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10c982f90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "th.backends.quantized.engine = \"qnnpack\"  # for ARM CPU\n",
    "th.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a239e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(th.nn.Module):\n",
    "    def __init__(self, input_dims, output_dims):\n",
    "        super().__init__()\n",
    "        self.quant = th.ao.quantization.QuantStub()\n",
    "        self.fc = th.nn.Linear(input_dims, output_dims, bias=False)\n",
    "        self.dequant = th.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af16c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = 10\n",
    "output_dims = 15\n",
    "m = Model(input_dims, output_dims)\n",
    "\n",
    "m.qconfig = th.ao.quantization.QConfig(\n",
    "    activation=th.ao.quantization.MovingAverageMinMaxObserver.with_args(\n",
    "        quant_min=-128,\n",
    "        quant_max=127,\n",
    "        dtype=th.qint8,\n",
    "        qscheme=th.per_tensor_symmetric,\n",
    "        reduce_range=False,\n",
    "    ),\n",
    "    weight=th.ao.quantization.MovingAverageMinMaxObserver.with_args(\n",
    "        quant_min=-128,\n",
    "        quant_max=127,\n",
    "        dtype=th.qint8,\n",
    "        qscheme=th.per_tensor_symmetric,\n",
    "        reduce_range=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Prepare\n",
    "pm = th.ao.quantization.prepare_qat(m)\n",
    "\n",
    "# Train\n",
    "pm(th.rand(32, input_dims))\n",
    "\n",
    "# Convert\n",
    "qm = th.ao.quantization.convert(pm.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25095119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float input: tensor([[0.8140, 0.6299, 0.6581, 0.5464, 0.6864, 0.3782, 0.3011, 0.0326, 0.1233,\n",
      "         0.7167]])\n",
      "\n",
      "Quantized input: tensor([[104,  80,  84,  70,  88,  48,  38,   4,  16,  91]], dtype=torch.int8)\n",
      "\n",
      "Float output: tensor([[-0.1863, -0.5974,  0.3148, -0.3276, -0.3918,  0.4111,  0.4754,  0.1221,\n",
      "         -0.1991,  0.0000, -0.0193,  0.1285, -0.4175,  0.1413,  0.1734]])\n",
      "\n",
      "Quantized output: tensor([[-29., -93.,  49., -51., -61.,  64.,  74.,  19., -31.,   0.,  -3.,  20.,\n",
      "         -65.,  22.,  27.]])\n",
      "\n",
      "Multiplier: tensor([6485986.])\n",
      "\n",
      "Quantized weights: tensor([  -1,   69, -105,  -94,  -49,   34,   -3,  101,  -11,   34,  -39,  -25,\n",
      "        -122,  -85,  -53,    5,   51,   77,  -87,  -56,   46,  106,  -26,   96,\n",
      "         -21,   14,  116, -119,  -80,  -32,  -50,  110,  -83,  -59,  -89, -120,\n",
      "         -75,  110,   57,   62,    7,  -66,   22, -119,  -92,  -66,   81,   75,\n",
      "         -57,   -5,   82,  127,   51,   17,   86,  -75,   24,  -99,  -89,  -66,\n",
      "          58,   51,  -76,   39,   70,  -16,    5,   30,   79,  123,  -98,  -47,\n",
      "          50,  106,  111,  113,   25, -111,   12,  -80, -119,  114,   97, -128,\n",
      "          24,  -22,  -21,  -59,   49,  -76,   47,   65,   91,   48, -127,  -83,\n",
      "          64,   27, -100,  -74,  120,   86,  -56,  -32, -122,   -2,  -96,  -99,\n",
      "          -7,   19,  -52,   76,  -78,  116,   88, -108,  -32,    6,   19,   30,\n",
      "          50,    8,  -62,   60, -123,  -76,  -32,  -62,  -45, -105,  -27,   27,\n",
      "         -83,   -7,   91,  -13,    4,  -11,   26,   81,  121,   81,  121,   -9,\n",
      "        -115,  -61,   87,   -1,  -64,  -98], dtype=torch.int8)\n",
      "\n",
      "Quantized bias: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "x = th.rand(1, input_dims)\n",
    "xq = qm.quant(x)\n",
    "y = qm(x)\n",
    "yq = th.round(y / qm.fc.scale)\n",
    "\n",
    "print(f\"Float input: {x}\\n\")\n",
    "print(f\"Quantized input: {xq.int_repr()}\\n\")\n",
    "print(f\"Float output: {y}\\n\")\n",
    "print(f\"Quantized output: {yq}\\n\")\n",
    "print(\n",
    "    f\"Multiplier: {th.round((qm.quant.scale * qm.fc.weight().q_scale() / qm.fc.scale) * (2**31))}\\n\"\n",
    ")\n",
    "print(f\"Quantized weights: {qm.fc.weight().int_repr().flatten()}\\n\")\n",
    "print(f\"Quantized bias: {qm.fc.bias()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a0434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
